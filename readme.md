## 2022/8/21
- 增加使用double dqn，dueling dqn, noisy network三种方法，希望能提高模型能力
- 增加了一层CNN深度
- 增加replay buffer最大容量
- 修改了游戏环境的保存，当出现dead时，会抛弃当前state，因为当前state会包含自机爆炸的动画，不属于错误决策发生时的真正state；同理，game over1部分出现done时，也会pop暂存replay的末项
- 每次截图+运算+move操作共计约0.11至0.12秒，游戏全速运行时在agent眼中仍然有不小的延迟，但是应该问题不大

## 2022/8/10

- 模型训练的代码没有完成
- 需要进一步研究各种超参数的设置
- 以上内容完成后训练一段时间观察效果

## 2022/8/12

- 完成结构
- 性能问题
  - 截图+操作: 0.02s
  - 截图+数据处理+随机探索+操作: 0.2-0.3s
  - 截图+数据处理+神经网络决策+操作: 0.3-0.4s
- 考虑2倍减速训练

## 2022/8/15

- img_stack修改
  - 从:[1,2,3,4] -> state0
  [2,3,4,5] -> state1
  修改为:[1,2,3,4] -> state0
  [5,6,7,8] -> state1
- 取消了图像按通道归一化的操作，怀疑会出现大量0或接近0的项，破坏图像信息
- 修改了minibatch策略，现在会随机取一小部分进行更新，而不会使用所有游戏的保存内容进行更新
- 在截图后用`cv2.resize`将图片长宽缩小为一半，这一步大大加快了numpy转tensor的过程，现在可以做到0.2-0.3秒进行一次运算，我认为可以支持原速运行
- 给截图增加了0.01秒的等待时间，避免截图速度过快导致位移特征不明显
- 增加了神经网络的宽度和深度，增加了cnn的深度和宽度，增加了池化层，增加了dense层的宽度

